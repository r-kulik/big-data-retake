{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d190de-784a-4e3e-86df-479162861ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = 'team38'\n",
    "\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafcad5a-520d-42a9-86a6-5eb7653921a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+-----+-----------+-----------------+----------------+----------------+---------------+-----+-----------+------------+---------------+----------------+-------------+-------------------+------------------+-----------+---------------+----------------------+-----------------------+---------+\n",
      "|   id|      price|apartment_type_id|metro_station_id|minutes_to_metro|number_of_rooms| area|living_area|kitchen_area|apartment_floor|number_of_floors|renovation_id|apartment_type_name|metro_station_name|region_name|renovation_name|metro_station_latitude|metro_station_longitude|region_id|\n",
      "+-----+-----------+-----------------+----------------+----------------+---------------+-----+-----------+------------+---------------+----------------+-------------+-------------------+------------------+-----------+---------------+----------------------+-----------------------+---------+\n",
      "|14399|1.5528071E7|                1|              93|            16.0|            2.0|66.73|       33.9|        15.2|            3.0|            25.0|            3|       New building|         курьяново|     Moscow|       Cosmetic|             55.649857|               37.70144|        1|\n",
      "|13078|  5950000.0|                2|             263|             3.0|            0.0| 20.0|       12.2|         5.1|            9.0|             9.0|            3|          Secondary|       рассказовка|     Moscow|       Cosmetic|              55.63397|              37.334755|        1|\n",
      "+-----+-----------+-----------------+----------------+----------------+---------------+-----+-----------+------------+---------------+----------------+-------------+-------------------+------------------+-----------+---------------+----------------------+-----------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"SHOW DATABASES\").show()\n",
    "spark.sql(\"USE team38_projectdb\").show()\n",
    "# spark.sql(\"SHOW TABLES\").show()\n",
    "spark.sql(\"SELECT * FROM housing_data_part_buck LIMIT 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cbcca46-a699-460d-ac8a-76b72bb2d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.sql(\"SELECT * FROM housing_data_part_buck\")\n",
    "\n",
    "# Split into train and test sets\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a797d81e-5fa4-4ae2-8e61-b839dcd1abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = [\n",
    "    'apartment_type_id', 'number_of_rooms', 'apartment_floor', 'number_of_floors', \n",
    "    'renovation_id', 'apartment_type_name', 'region_name', 'renovation_name'\n",
    "]\n",
    "\n",
    "# StringIndexer and OneHotEncoder for categorical columns\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid=\"keep\") for column in categorical_columns]\n",
    "encoders = [OneHotEncoder(inputCol=column + \"_index\", outputCol=column + \"_encoded\") for column in categorical_columns]\n",
    "\n",
    "# Assemble features\n",
    "numeric_columns = [\n",
    "    'id', 'minutes_to_metro', 'area', 'living_area', 'kitchen_area', \n",
    "    'metro_station_latitude', 'metro_station_longitude', 'region_id'\n",
    "]\n",
    "\n",
    "assembler_inputs = [column + \"_encoded\" for column in categorical_columns] + numeric_columns\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# Target variable\n",
    "label_column = \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e582696c-5413-48f1-bf87-60894312d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb49d03-cf98-4642-a28c-721cab759273",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Transform the training and testing data\n",
    "train_transformed = pipeline_model.transform(train_df).select(\"scaledFeatures\", label_column)\n",
    "test_transformed = pipeline_model.transform(test_df).select(\"scaledFeatures\", label_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e586fc4-358e-425b-b3bb-3482be0fcfed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
