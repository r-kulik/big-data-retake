{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9488942b-39c9-4618-8619-9983ff4af89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import tqdm\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = \"team38\"\n",
    "\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3463bc1-ae18-42df-8a86-45af63f7e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+---------------+-----+-----------+------------+---------------+----------------+-------------------+-----------+------------------+----------------------+-----------------------+\n",
      "|       price|minutes_to_metro|number_of_rooms| area|living_area|kitchen_area|apartment_floor|number_of_floors|apartment_type_name|region_name|   renovation_name|metro_station_latitude|metro_station_longitude|\n",
      "+------------+----------------+---------------+-----+-----------+------------+---------------+----------------+-------------------+-----------+------------------+----------------------+-----------------------+\n",
      "| 1.5528071E7|            16.0|            2.0|66.73|       33.9|        15.2|            3.0|            25.0|       New building|     Moscow|          Cosmetic|             55.649857|               37.70144|\n",
      "|   5950000.0|             3.0|            0.0| 20.0|       12.2|         5.1|            9.0|             9.0|          Secondary|     Moscow|          Cosmetic|              55.63397|              37.334755|\n",
      "|   4950000.0|             6.0|            0.0| 20.0|       12.2|         8.3|            2.0|            23.0|          Secondary|     Moscow|Without renovation|              55.63397|              37.334755|\n",
      "|   5450000.0|            17.0|            0.0| 17.1|       10.0|         2.0|            6.0|             6.0|          Secondary|     Moscow|          Cosmetic|             55.794613|              37.799427|\n",
      "|   5140000.0|            17.0|            0.0| 17.1|       10.0|         2.0|            6.0|             6.0|          Secondary|     Moscow|          Cosmetic|             55.794613|              37.799427|\n",
      "|   3750000.0|            16.0|            0.0| 14.7|        9.6|         7.9|            1.0|             5.0|          Secondary|     Moscow|          Cosmetic|             55.794613|              37.799427|\n",
      "|     1.125E7|            21.0|            0.0| 27.1|       24.0|         8.9|            4.0|             8.0|          Secondary|     Moscow|Without renovation|             55.796127|              37.588108|\n",
      "|   4950000.0|             6.0|            0.0| 20.0|       12.2|         8.3|            2.0|            23.0|          Secondary|     Moscow|          Cosmetic|              55.63397|              37.334755|\n",
      "|   9199999.0|            18.0|            0.0| 27.6|       18.3|         4.0|            4.0|            12.0|          Secondary|     Moscow|          Cosmetic|              55.63397|              37.334755|\n",
      "|     1.088E7|             9.0|            0.0| 19.9|       12.2|         8.3|           11.0|            33.0|          Secondary|     Moscow|          Cosmetic|              55.67058|              37.449013|\n",
      "|      2.49E7|            14.0|            4.0|108.3|       73.0|         9.0|            4.0|             5.0|          Secondary|     Moscow|          Cosmetic|              55.67058|              37.449013|\n",
      "|4.78455008E8|             7.0|            5.0|245.9|      155.0|        24.3|            2.0|             8.0|          Secondary|     Moscow|Without renovation|             55.735306|               37.59287|\n",
      "|4.86432512E8|             7.0|            6.0|245.9|      126.4|        27.0|            2.0|             8.0|          Secondary|     Moscow|Without renovation|             55.735306|               37.59287|\n",
      "|      4.75E7|            12.0|            4.0|113.3|       67.9|        15.0|           13.0|            26.0|          Secondary|     Moscow|Without renovation|             55.818104|               37.43525|\n",
      "|      1.31E7|            16.0|            3.0| 58.8|       31.9|        11.5|            8.0|             9.0|          Secondary|     Moscow|          Cosmetic|             55.716576|               37.81591|\n",
      "|       3.8E7|             9.0|            3.0| 89.5|       62.1|         8.0|            2.0|             8.0|          Secondary|     Moscow|Without renovation|              55.76082|               37.58128|\n",
      "|       1.5E7|            14.0|            3.0| 64.0|       40.0|         9.0|            5.0|             9.0|          Secondary|     Moscow|          Cosmetic|             55.716576|               37.81591|\n",
      "|       2.0E7|            14.0|            3.0| 83.7|       48.0|        12.0|           12.0|            20.0|          Secondary|     Moscow|Without renovation|              55.63397|              37.334755|\n",
      "|      1.43E7|            13.0|            3.0| 56.5|       36.0|         6.0|            5.0|             9.0|          Secondary|     Moscow|          Cosmetic|             55.716576|               37.81591|\n",
      "|       6.5E7|            10.0|            3.0| 83.7|       28.4|        31.7|           14.0|            32.0|          Secondary|     Moscow|          Cosmetic|             55.736935|               37.51601|\n",
      "+------------+----------------+---------------+-----+-----------+------------+---------------+----------------+-------------------+-----------+------------------+----------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE team38_projectdb\")\n",
    "\n",
    "# Execute the optimized SQL query and convert the result to a DataFrame\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        price, \n",
    "        minutes_to_metro, \n",
    "        number_of_rooms, \n",
    "        area, \n",
    "        living_area, \n",
    "        kitchen_area, \n",
    "        apartment_floor, \n",
    "        number_of_floors, \n",
    "        apartment_type_name, \n",
    "        region_name, \n",
    "        renovation_name, \n",
    "        metro_station_latitude, \n",
    "        metro_station_longitude \n",
    "    FROM \n",
    "        housing_data_part_buck\n",
    "\"\"\")\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaabd51d-cd46-46aa-9abd-d81c6448dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, mean as _mean, stddev as _stddev, abs as abs_func\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.sql.functions import rand\n",
    "import time\n",
    "\n",
    "# Assuming df is your DataFrame with the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a426c23-42a2-4c5d-880d-6013112df164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Split the data into train and test sets (80/20) with random state = 42\n",
    "train_data, test_data = df.orderBy(rand(seed=42)).randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 2: Identify categorical columns\n",
    "categorical_columns = [\n",
    "    'apartment_type_name', \n",
    "    'region_name', \n",
    "    'renovation_name', \n",
    "]\n",
    "\n",
    "# Step 3: Identify numeric columns\n",
    "numeric_columns = [\n",
    "    'minutes_to_metro', \n",
    "    'number_of_rooms', \n",
    "    'area', \n",
    "    'living_area', \n",
    "    'kitchen_area', \n",
    "    'apartment_floor', \n",
    "    'number_of_floors', \n",
    "    'metro_station_latitude', \n",
    "    'metro_station_longitude'\n",
    "]\n",
    "\n",
    "# Step 4: Create StringIndexer and OneHotEncoder stages\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\") for col in categorical_columns]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_encoded\") for col in categorical_columns]\n",
    "\n",
    "# Step 5: Create a feature for the ratio of living area to total area\n",
    "train_data = train_data.withColumn(\"living_area_ratio\", col(\"living_area\") / col(\"area\"))\n",
    "test_data = test_data.withColumn(\"living_area_ratio\", col(\"living_area\") / col(\"area\"))\n",
    "\n",
    "# Update numeric columns to include the new feature\n",
    "numeric_columns.append(\"living_area_ratio\")\n",
    "\n",
    "# Step 6: Create a VectorAssembler to combine all features into a single vector column\n",
    "assembler_inputs = [col + \"_encoded\" for col in categorical_columns] + numeric_columns\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# Step 7: Feature scaling\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "\n",
    "# Step 8: Create the pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler])\n",
    "\n",
    "# Step 9: Fit the pipeline on the training data\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Step 10: Transform the training and test data\n",
    "train_data = model.transform(train_data)\n",
    "test_data = model.transform(test_data)\n",
    "\n",
    "# Step 11: Select only the features and label columns\n",
    "train_data = train_data.select(\"scaled_features\", \"price\")\n",
    "test_data = test_data.select(\"scaled_features\", \"price\")\n",
    "\n",
    "# Step 12: Rename the label column to 'label'\n",
    "train_data = train_data.withColumnRenamed(\"price\", \"label\")\n",
    "test_data = test_data.withColumnRenamed(\"price\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dee6d717-0c69-43e3-a8a0-c42506d9d480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|     scaled_features|    label|\n",
      "+--------------------+---------+\n",
      "|[0.85555047711956...|1150000.0|\n",
      "|[0.85555047711956...|1420000.0|\n",
      "|[0.85555047711956...|1750000.0|\n",
      "|[-1.1687738602762...|1939125.0|\n",
      "|[-1.1687738602762...|1939125.0|\n",
      "|[-1.1687738602762...|1939125.0|\n",
      "|[-1.1687738602762...|1941650.0|\n",
      "|[-1.1687738602762...|1963875.0|\n",
      "|[-1.1687738602762...|1972470.0|\n",
      "|[-1.1687738602762...|1984900.0|\n",
      "|[-1.1687738602762...|2261523.0|\n",
      "|[-1.1687738602762...|2278998.0|\n",
      "|[-1.1687738602762...|2278998.0|\n",
      "|[0.85555047711956...|2390000.0|\n",
      "|[-1.1687738602762...|2477950.0|\n",
      "|[0.85555047711956...|2540000.0|\n",
      "|[-1.1687738602762...|2583125.0|\n",
      "|[-1.1687738602762...|2583125.0|\n",
      "|[-1.1687738602762...|2583125.0|\n",
      "|[-1.1687738602762...|2595000.0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c0e41f-0fe7-4639-959a-3bfa1aeb04d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to run commands\n",
    "import os\n",
    "def run(command):\n",
    "    return os.popen(command).read()\n",
    "\n",
    "# Save train_data\n",
    "train_data.select(\"scaled_features\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/train\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/train/*.json > data/train.json\")\n",
    "\n",
    "# Save test_data\n",
    "test_data.select(\"scaled_features\", \"label\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/test\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/test/*.json > data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "948eefc5-9232-413b-9edc-634c44725b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Evaluation:\n",
      "Root Mean Squared Error (RMSE): 58172214.72593775\n",
      "R^2: 0.6167264731353712\n",
      "Mean Absolute Error (MAE): 21030107.34068811\n",
      "Mean Absolute Percentage Error (MAPE): 99.37805144138096\n",
      "+---------+--------------------+\n",
      "|    label|          prediction|\n",
      "+---------+--------------------+\n",
      "|1560000.0| -1717532.5268334672|\n",
      "|1939125.0|-1.758145106925191E7|\n",
      "|1941650.0|-1.64189609519939...|\n",
      "|2218450.0|-1.977625844864788E7|\n",
      "|2540000.0|-1.53238440084085...|\n",
      "|2583125.0|  -9290651.840316996|\n",
      "|2600000.0|  -4228712.566564754|\n",
      "|2607300.0|-1.05631503843554...|\n",
      "|2630625.0|   -9575456.72697375|\n",
      "|2630640.0|  -9037473.706536181|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.sql.functions import abs, col, mean\n",
    "\n",
    "# Step 1: Initialize the Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"label\")\n",
    "\n",
    "# Step 2: Create a parameter grid for grid search\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Step 3: Set up the TrainValidationSplit for cross-validation\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Step 4: Fit the model on the training data\n",
    "lr_model = tvs.fit(train_data)\n",
    "\n",
    "# Step 5: Save the best Linear Regression model to HDFS\n",
    "lr_model.bestModel.write().overwrite().save(\"project/models/model1\")\n",
    "\n",
    "# Step 6: Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Step 7: Save the prediction results to HDFS\n",
    "predictions.select(\"label\", \"prediction\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .save(\"project/output/model1_predictions\")\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "rmse1 = evaluator_rmse.evaluate(predictions)\n",
    "r21 = evaluator_r2.evaluate(predictions)\n",
    "mae1 = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "# Step 9: Calculate MAPE manually\n",
    "predictions = predictions.withColumn(\"APE\", abs((col(\"label\") - col(\"prediction\")) / col(\"label\")))\n",
    "mape1 = predictions.select(mean(\"APE\")).collect()[0][0] * 100\n",
    "\n",
    "print(f\"Linear Regression Model Evaluation:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse1}\")\n",
    "print(f\"R^2: {r21}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae1}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape1}\")\n",
    "\n",
    "# Step 10: Show some predictions\n",
    "predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b10a9fa-2ef2-497c-b81a-10d95d975dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT Model Evaluation:\n",
      "Root Mean Squared Error (RMSE): 60683249.613260634\n",
      "R^2: 0.5829239183171425\n",
      "Mean Absolute Error (MAE): 11437773.092258744\n",
      "Mean Absolute Percentage Error (MAPE): 18.154998573806175\n",
      "+---------+------------------+\n",
      "|    label|        prediction|\n",
      "+---------+------------------+\n",
      "|1560000.0|3044949.5050197914|\n",
      "|1939125.0|2697327.7442573826|\n",
      "|1941650.0| 2552123.407877258|\n",
      "|2218450.0|2672443.3557320675|\n",
      "|2540000.0| 4755423.864178333|\n",
      "|2583125.0| 2620496.707959361|\n",
      "|2600000.0| 4349562.082554642|\n",
      "|2607300.0|2703614.6421105964|\n",
      "|2630625.0|2680754.6625601375|\n",
      "|2630640.0|2680754.6625601375|\n",
      "+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.sql.functions import abs, col, mean\n",
    "\n",
    "# Step 1: Initialize the GBT model\n",
    "gbt = GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"label\")\n",
    "\n",
    "# Step 2: Create a parameter grid for grid search\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [2, 4]) \\\n",
    "    .addGrid(gbt.maxIter, [3, 5]) \\\n",
    "    .build()\n",
    "\n",
    "# Step 3: Set up the TrainValidationSplit for cross-validation\n",
    "tvs = TrainValidationSplit(estimator=gbt,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                           trainRatio=0.8)\n",
    "\n",
    "# Step 4: Fit the model on the training data\n",
    "gbt_model = tvs.fit(train_data)\n",
    "\n",
    "# Step 5: Save the best GBT model to HDFS\n",
    "gbt_model.bestModel.write().overwrite().save(\"project/models/model2\")\n",
    "\n",
    "# Step 6: Make predictions on the test data\n",
    "predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Step 7: Save the prediction results to HDFS\n",
    "predictions.select(\"label\", \"prediction\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .save(\"project/output/model2_predictions\")\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "rmse2 = evaluator_rmse.evaluate(predictions)\n",
    "r22 = evaluator_r2.evaluate(predictions)\n",
    "mae2 = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "# Step 9: Calculate MAPE manually\n",
    "predictions = predictions.withColumn(\"APE\", abs((col(\"label\") - col(\"prediction\")) / col(\"label\")))\n",
    "mape2 = predictions.select(mean(\"APE\")).collect()[0][0] * 100\n",
    "\n",
    "print(f\"GBT Model Evaluation:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse2}\")\n",
    "print(f\"R^2: {r22}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae2}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape2}\")\n",
    "\n",
    "# Step 10: Show some predictions\n",
    "predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daa1d0e4-d276-4225-bc78-c432f2988d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+------------------+--------------------+------------------+\n",
      "|model            |RMSE                |R2                |MAE                 |MAPE              |\n",
      "+-----------------+--------------------+------------------+--------------------+------------------+\n",
      "|Linear Regression|5.817221472593775E7 |0.6167264731353712|2.103010734068811E7 |99.37805144138096 |\n",
      "|GBT              |6.0683249613260634E7|0.5829239183171425|1.1437773092258744E7|18.154998573806175|\n",
      "+-----------------+--------------------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame to report performance of the models\n",
    "models = [\n",
    "    [\"Linear Regression\", rmse1, r21, mae1, mape1],\n",
    "    [\"GBT\", rmse2, r22, mae2, mape2]\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(models, [\"model\", \"RMSE\", \"R2\", \"MAE\", \"MAPE\"])\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Save it to HDFS\n",
    "df.coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .save(\"project/output/evaluation.csv\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/output/evaluation.csv/*.csv > output/evaluation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
